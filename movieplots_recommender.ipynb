{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec, Phrases\n",
    "from gensim.parsing.preprocessing import STOPWORDS as stop_words\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "\n",
    "# import csv file \n",
    "df_moviedetails = pd.read_csv('export_moviedetails_full_v2.csv', sep=',', encoding='iso-8859-1', escapechar='\\\\')\n",
    "\n",
    "# drop duplicate record based movie_url\n",
    "df_moviedetails.drop_duplicates(subset =\"movie_url\", keep = False, inplace = True) \n",
    "\n",
    "# metascore and world wide gross have lot of missing data, while user rating is complete\n",
    "# transform the user rating column into GOOD and BAD where GOOD: (>6), BAD: (<=6) \n",
    "df_moviedetails['rating-enc'] = np.where(df_moviedetails['user_rating'] >6 , \"GOOD\", \"BAD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate movie title and plot summary \n",
    "df_moviedetails[\"title_plot\"] = df_moviedetails[\"movie_title\"].astype(str).str.cat(df_moviedetails[\"plot_summary\"].astype(str), sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ganfam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_url</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>https://www.imdb.com/title/tt9016974/</td>\n",
       "      <td>Synchronic</td>\n",
       "      <td>Synchronic  two new orleans paramedic life rip...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt9016974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>https://www.imdb.com/title/tt4154796/</td>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>Avengers: Endgame  after devastating event ofa...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt4154796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>https://www.imdb.com/title/tt9608818/</td>\n",
       "      <td>The Friend</td>\n",
       "      <td>The Friend  after receiving lifealtering news ...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt9608818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>https://www.imdb.com/title/tt5363618/</td>\n",
       "      <td>Sound of Metal</td>\n",
       "      <td>Sound of Metal  a heavymetal drummer life thro...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt5363618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>https://www.imdb.com/title/tt8367814/</td>\n",
       "      <td>The Gentlemen</td>\n",
       "      <td>The Gentlemen  an american expat try sell high...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt8367814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4995</td>\n",
       "      <td>https://www.imdb.com/title/tt4170186/</td>\n",
       "      <td>Beeba Boys</td>\n",
       "      <td>Beeba Boys  with help recent recruit gang lead...</td>\n",
       "      <td>BAD</td>\n",
       "      <td>tt4170186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4996</td>\n",
       "      <td>https://www.imdb.com/title/tt4947084/</td>\n",
       "      <td>Anarkali</td>\n",
       "      <td>Anarkali  the story naval officer fall love go...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt4947084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4997</td>\n",
       "      <td>https://www.imdb.com/title/tt5143700/</td>\n",
       "      <td>La guerre des tuques 3D</td>\n",
       "      <td>La guerre des tuques 3D  when winter break arr...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt5143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4998</td>\n",
       "      <td>https://www.imdb.com/title/tt4257950/</td>\n",
       "      <td>Russell Madness</td>\n",
       "      <td>Russell Madness  when man inherits grandfather...</td>\n",
       "      <td>BAD</td>\n",
       "      <td>tt4257950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>https://www.imdb.com/title/tt8311958/</td>\n",
       "      <td>Divino Amor</td>\n",
       "      <td>Divino Amor A woman uses her bureaucratic job ...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt8311958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4999 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  movie_url              movie_title  \\\n",
       "0     https://www.imdb.com/title/tt9016974/               Synchronic   \n",
       "1     https://www.imdb.com/title/tt4154796/        Avengers: Endgame   \n",
       "2     https://www.imdb.com/title/tt9608818/               The Friend   \n",
       "3     https://www.imdb.com/title/tt5363618/           Sound of Metal   \n",
       "4     https://www.imdb.com/title/tt8367814/            The Gentlemen   \n",
       "...                                     ...                      ...   \n",
       "4995  https://www.imdb.com/title/tt4170186/               Beeba Boys   \n",
       "4996  https://www.imdb.com/title/tt4947084/                 Anarkali   \n",
       "4997  https://www.imdb.com/title/tt5143700/  La guerre des tuques 3D   \n",
       "4998  https://www.imdb.com/title/tt4257950/          Russell Madness   \n",
       "5000  https://www.imdb.com/title/tt8311958/              Divino Amor   \n",
       "\n",
       "                                                   text label   movie_id  \n",
       "0     Synchronic  two new orleans paramedic life rip...  GOOD  tt9016974  \n",
       "1     Avengers: Endgame  after devastating event ofa...  GOOD  tt4154796  \n",
       "2     The Friend  after receiving lifealtering news ...  GOOD  tt9608818  \n",
       "3     Sound of Metal  a heavymetal drummer life thro...  GOOD  tt5363618  \n",
       "4     The Gentlemen  an american expat try sell high...  GOOD  tt8367814  \n",
       "...                                                 ...   ...        ...  \n",
       "4995  Beeba Boys  with help recent recruit gang lead...   BAD  tt4170186  \n",
       "4996  Anarkali  the story naval officer fall love go...  GOOD  tt4947084  \n",
       "4997  La guerre des tuques 3D  when winter break arr...  GOOD  tt5143700  \n",
       "4998  Russell Madness  when man inherits grandfather...   BAD  tt4257950  \n",
       "5000  Divino Amor A woman uses her bureaucratic job ...  GOOD  tt8311958  \n",
       "\n",
       "[4999 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe df with subset of columns for text analytics\n",
    "df = df_moviedetails[[\"movie_url\",\"movie_title\",\"title_plot\",\"rating-enc\"]]\n",
    "\n",
    "# instead of the default index, extract imdb movie ID from url and set it as index\n",
    "df[\"movie_id\"] = df[\"movie_url\"].str.split(\"/\").str[-2]\n",
    "#df = df.set_index(\"movie_id\")\n",
    "\n",
    "# rename key columns' name\n",
    "df = df.rename(columns={'title_plot': 'text','rating-enc': 'label'})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_url      False\n",
       "movie_title    False\n",
       "text           False\n",
       "label          False\n",
       "movie_id       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values in df\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_url</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>https://www.imdb.com/title/tt9016974/</td>\n",
       "      <td>Synchronic</td>\n",
       "      <td>synchronic two new orleans paramedic life rip...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt9016974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>https://www.imdb.com/title/tt4154796/</td>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>avengers endgame devastating event ofavengers...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt4154796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>https://www.imdb.com/title/tt9608818/</td>\n",
       "      <td>The Friend</td>\n",
       "      <td>friend receiving lifealtering news couple fin...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt9608818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>https://www.imdb.com/title/tt5363618/</td>\n",
       "      <td>Sound of Metal</td>\n",
       "      <td>sound metal heavymetal drummer life thrown fr...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt5363618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>https://www.imdb.com/title/tt8367814/</td>\n",
       "      <td>The Gentlemen</td>\n",
       "      <td>gentlemen american expat try sell highly prof...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>tt8367814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               movie_url        movie_title  \\\n",
       "0  https://www.imdb.com/title/tt9016974/         Synchronic   \n",
       "1  https://www.imdb.com/title/tt4154796/  Avengers: Endgame   \n",
       "2  https://www.imdb.com/title/tt9608818/         The Friend   \n",
       "3  https://www.imdb.com/title/tt5363618/     Sound of Metal   \n",
       "4  https://www.imdb.com/title/tt8367814/      The Gentlemen   \n",
       "\n",
       "                                                text label   movie_id  \n",
       "0   synchronic two new orleans paramedic life rip...  GOOD  tt9016974  \n",
       "1   avengers endgame devastating event ofavengers...  GOOD  tt4154796  \n",
       "2   friend receiving lifealtering news couple fin...  GOOD  tt9608818  \n",
       "3   sound metal heavymetal drummer life thrown fr...  GOOD  tt5363618  \n",
       "4   gentlemen american expat try sell highly prof...  GOOD  tt8367814  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "text preprocessing - convert to lower case, remove non-word characters, remove spaces from the start\n",
    "tokenization, then remove stop words. Then save the processed words back to text field.  \n",
    "\"\"\"\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "newStopWords = ['his', 'like', \"she'll\", 'than', 'also', 'only', \"you're\", 'through', 'about', 'themselves', \"aren't\", 'above', 'after', \"that's\", 'before', 'com', 'she', \"she's\", \"who's\", 'has', 'any', \"didn't\", \"i'd\", \"we've\", 'the', 'other', 'else', 'at', 'down', \"here's\", 'further', 'there', 'these', 'by', 'get', \"they'll\", 'no', \"where's\", \"shouldn't\", 'then', 'himself', 'hers', 'out', \"we'll\", 'an', 'should', 'under', \"let's\", 'what', 'if', \"isn't\", \"he'll\", 'or', \"shan't\", 'too', 'same', 'this', \"hasn't\", \"haven't\", 'me', 'had', \"they've\", 'could', 'all', 'some', 'into', 'he', 'until', 'again', 'http', 'k', \"hadn't\", \"couldn't\", \"i'll\", \"we'd\", 'between', 'ourselves', \"when's\", 'for', 'doing', 'nor', 'which', 'our', 'was', 'such', 'very', 'own', 'on', 'being', 'am', 'yours', 'would', 'my', 'once', \"they'd\", 'how', 'to', 'more', 'theirs', 'did', 'when', \"can't\", 'www', 'does', 'those', 'both', \"mustn't\", 'ought', \"weren't\", 'were', 'therefore', 'here', 'over', 'with', 'it', 'not', \"you've\", \"i'm\", 'hence', 'against', \"she'd\", 'her', 'their', \"it's\", 'can', 'having', 'of', 'they', 'have', 'in', 'itself', 'just', 'from', \"how's\", 'i', 'we', 'and', 'shall', 'few', 'since', 'whom', 'while', 'you', 'be', 'yourself', \"what's\", \"you'll\", 'but', 'yourselves', 'below', 'herself', \"i've\", 'why', 'during', \"he'd\", 'who', 'off', 'otherwise', 'been', 'that', \"you'd\", 'myself', 'because', 'up', \"we're\", 'as', \"wasn't\", 'your', \"there's\", 'him', 'a', 'ours', 'r', 'ever', 'where', \"they're\", 'are', 'is', \"he's\", \"don't\", \"doesn't\", 'cannot', 'each', 'its', 'them', 'however', 'so', \"why's\", 'most', \"wouldn't\", \"won't\", 'do']\n",
    "stop_words.extend(newStopWords)\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "for index, row in df.iterrows():\n",
    "    filter_sentence = ''\n",
    "    sentence = str(row['text']).lower()\n",
    "    # Cleaning the sentence with regex\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    # Tokenization\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    # Stopwords removal\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # Lemmatization\n",
    "    for words in words:\n",
    "        filter_sentence = filter_sentence  + ' ' + str(words)\n",
    "    \n",
    "    df.loc[index, 'text'] = filter_sentence\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec, Phrases\n",
    "\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(df['text'])]\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_recommender(n):\n",
    "    print('movies : ' + df.loc[[n]].movie_title.item())\n",
    "    print('summary : ' + df.loc[[n]].text.item().strip())\n",
    "    print('\\n')\n",
    "    print('searching similiar movies......') \n",
    "    print('\\n')\n",
    "    \n",
    "    sims = model.docvecs.most_similar(n)\n",
    "    \n",
    "    for tagged in sims:\n",
    "        print(str(tagged[0]) + '. ' + df.loc[[tagged[0]]].movie_title.item())\n",
    "        print('summary : ' + df.loc[[tagged[0]]].text.item().strip())\n",
    "        print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies : The Friend\n",
      "summary : friend receiving lifealtering news couple find unexpected support best friend put life hold move family home bringing impact much greater profound anyone imagined\n",
      "\n",
      "\n",
      "searching similiar movies......\n",
      "\n",
      "\n",
      "2042. The Death of Stalin\n",
      "summary : death stalin moscow 1953 power nearly thirty year soviet dictator joseph vissarionovich stalin adrian mcloughlin take ill quickly dy member council ministers scramble power\n",
      "\n",
      "\n",
      "3798. The Phenom\n",
      "summary : phenom rookie pitcher undergoes psychotherapy overcome yip\n",
      "\n",
      "\n",
      "2014. It\n",
      "summary : summer 1989 group bullied kid band together destroy shapeshifting monster disguise clown prey child derry small maine town\n",
      "\n",
      "\n",
      "2482. Unhinged\n",
      "summary : unhinged four american best friend decide take back road travelling wedding england way deadly secret force girl stranded wood discover house occupied miss perkins\n",
      "\n",
      "\n",
      "4828. Ich bin dann mal weg\n",
      "summary : ich bin dann mal weg based book ich bin dann mal weg hape kerkeling author describes journey way st james pilgrimage route people encounter\n",
      "\n",
      "\n",
      "749. 37 sekanzu\n",
      "summary : 37 sekanzu yuma young japanese woman suffers cerebral palsy torn obligation towards family dream become manga artist struggle lead selfdetermined life\n",
      "\n",
      "\n",
      "1697. Twisted Pair\n",
      "summary : twisted pair identical twin brother become hybrid ai artificial intelligence entity yet torn different direction achieve justice humanity\n",
      "\n",
      "\n",
      "4328. The Daughter\n",
      "summary : daughter story follows man return home discover longburied family secret whose attempt put thing right threaten life left home year\n",
      "\n",
      "\n",
      "3277. Queen of Katwe\n",
      "summary : queen katwe ugandan girl see world rapidly change introduced game chess\n",
      "\n",
      "\n",
      "1672. GenÃ¨se\n",
      "summary : genãse three teenager shaken first love turmoil youth time others conforming stand ground assert right love free\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ganfam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  \n",
      "C:\\Users\\ganfam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\ganfam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\ganfam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "movie_recommender(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
